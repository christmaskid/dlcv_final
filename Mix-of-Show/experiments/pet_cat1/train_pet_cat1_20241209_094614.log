2024-12-09 09:46:14,509 INFO: 
Version Information: 
OpenStory
	PyTorch: 2.3.1+cu121
	TorchVision: 0.18.1+cu121
2024-12-09 09:46:14,509 INFO: 
  name: pet_cat1
  model_type: EDLoraModel
  world_size: 1
  num_gpu: 1
  manual_seed: 0
  datasets:[
    train:[
      name: LoraDataset
      type: LoraDataset
      concept_list: /content/Data/jsons/pet_cat1.json
      use_caption: True
      instance_transform: [OrderedDict([('type', 'Resize'), ('size', 512)]), OrderedDict([('type', 'HumanResizeCropFinal'), ('size', 512), ('crop_p', 0.5)]), OrderedDict([('type', 'ToTensor')]), OrderedDict([('type', 'Normalize'), ('mean', [0.5]), ('std', [0.5])]), OrderedDict([('type', 'ShuffleCaption'), ('keep_token_num', 1)]), OrderedDict([('type', 'EnhanceText'), ('enhance_type', 'human')])]
      replace_mapping:[
        <TOK>: <pet_cat1_1> <pet_cat1_2>
      ]
      dataset_enlarge_ratio: 100
      use_shuffle: True
      num_worker_per_gpu: 2
      batch_size_per_gpu: 1
      pin_memory: True
      prefetch_mode: cuda
      phase: train
    ]
    val_vis:[
      name: PromptDataset
      type: PromptDataset
      prompts: /content/dlcv_final/Mix-of-Show/datasets/validation_prompts/val.txt
      num_samples_per_prompt: 1
      latent_size: [4, 64, 64]
      replace_mapping:[
        <TOK>: <pet_cat1_1> <pet_cat1_2>
      ]
      use_shuffle: False
      num_worker_per_gpu: 2
      batch_size_per_gpu: 1
      phase: val
    ]
  ]
  network_g:[
    type: EDLoRA
    pretrained_path: experiments/pretrained_models/stable-diffusion-v1-4
    finetune_cfg:[
      text_embedding:[
        enable_tuning: True
        lr: 0.001
      ]
      text_encoder:[
        enable_tuning: True
        lora_cfg:[
          rank: 4
          alpha: 1
          where: CLIPSdpaAttention
        ]
        lr: 1e-05
      ]
      unet:[
        enable_tuning: True
        lora_cfg:[
          rank: 4
          alpha: 1
          where: CrossAttention
        ]
        lr: 0.0001
      ]
    ]
    new_concept_token: <pet_cat1_1>+<pet_cat1_2>
    noise_offset: 0.01
    initializer_token: <rand-0.013>+cat
    sd_version: v1
    test_sampler_type: ddim
  ]
  path:[
    pretrain_network_g: None
    experiments_root: /content/dlcv_final/Mix-of-Show/experiments/pet_cat1
    models: /content/dlcv_final/Mix-of-Show/experiments/pet_cat1/models
    training_states: /content/dlcv_final/Mix-of-Show/experiments/pet_cat1/training_states
    log: /content/dlcv_final/Mix-of-Show/experiments/pet_cat1
    visualization: /content/dlcv_final/Mix-of-Show/experiments/pet_cat1/visualization
  ]
  train:[
    optim_g:[
      type: AdamW
      lr: 0.0
      scale_lr: False
      weight_decay: 0.01
      betas: [0.9, 0.999]
    ]
    kde_opt:[
      type: KDELoss
      loss_weight: 0.002
      bandwidth: 0.5
    ]
    drop_start_iter: -1
    unet_kv_drop_rate: 0.0
    scheduler:[
      type: LinearLR
      num_epochs: 1000
    ]
    total_iter: 1000
    warmup_iter: -1
  ]
  val:[
    val_freq: 1000.0
    save_img: True
    compose_visualize: True
    pbar: True
    suffix: None
    sample:[
      num_inference_steps: 50
      guidance_scale: 7.5
    ]
    metrics: None
  ]
  logger:[
    print_freq: 10
    save_checkpoint_freq: 200.0
    use_tb_logger: False
    wandb:[
      project: None
      resume_id: None
    ]
  ]
  dist_params:[
    backend: nccl
    port: 29500
  ]
  dist: True
  rank: 0
  auto_resume: False
  is_train: True
  root_path: /content/dlcv_final/Mix-of-Show

2024-12-09 09:46:14,510 INFO: Transform [Resize] is created.
2024-12-09 09:46:14,510 INFO: Transform [HumanResizeCropFinal] is created.
2024-12-09 09:46:14,510 INFO: Transform [ToTensor] is created.
2024-12-09 09:46:14,510 INFO: Transform [Normalize] is created.
2024-12-09 09:46:14,510 INFO: Transform [ShuffleCaption] is created.
2024-12-09 09:46:14,510 INFO: Transform [EnhanceText] is created.
2024-12-09 09:46:14,510 INFO: Dataset [LoraDataset] - LoraDataset is built.
2024-12-09 09:46:14,511 INFO: Training statistics:
	Number of train images: 5
	Dataset enlarge ratio: 100
	Batch size per gpu: 1
	World size (gpu number): 1
	Require iter number per epoch: 500
	Total epochs: 2; iters: 1000.
2024-12-09 09:46:14,511 INFO: Dataset [PromptDataset] - PromptDataset is built.
2024-12-09 09:46:14,511 INFO: Number of val images/folders in PromptDataset: 1
2024-12-09 09:46:15,881 INFO: 49408 is random initialized by: <rand-0.013>
2024-12-09 09:46:15,881 INFO: 49409 is random initialized by: <rand-0.013>
2024-12-09 09:46:15,881 INFO: 49410 is random initialized by: <rand-0.013>
2024-12-09 09:46:15,881 INFO: 49411 is random initialized by: <rand-0.013>
2024-12-09 09:46:15,881 INFO: 49412 is random initialized by: <rand-0.013>
2024-12-09 09:46:15,881 INFO: 49413 is random initialized by: <rand-0.013>
2024-12-09 09:46:15,882 INFO: 49414 is random initialized by: <rand-0.013>
2024-12-09 09:46:15,882 INFO: 49415 is random initialized by: <rand-0.013>
2024-12-09 09:46:15,882 INFO: 49416 is random initialized by: <rand-0.013>
2024-12-09 09:46:15,882 INFO: 49417 is random initialized by: <rand-0.013>
2024-12-09 09:46:15,882 INFO: 49418 is random initialized by: <rand-0.013>
2024-12-09 09:46:15,882 INFO: 49419 is random initialized by: <rand-0.013>
2024-12-09 09:46:15,882 INFO: 49420 is random initialized by: <rand-0.013>
2024-12-09 09:46:15,882 INFO: 49421 is random initialized by: <rand-0.013>
2024-12-09 09:46:15,882 INFO: 49422 is random initialized by: <rand-0.013>
2024-12-09 09:46:15,882 INFO: 49423 is random initialized by: <rand-0.013>
2024-12-09 09:46:16,546 INFO: 49424 is random initialized by: cat, 2368
2024-12-09 09:46:16,546 INFO: 49425 is random initialized by: cat, 2368
2024-12-09 09:46:16,547 INFO: 49426 is random initialized by: cat, 2368
2024-12-09 09:46:16,547 INFO: 49427 is random initialized by: cat, 2368
2024-12-09 09:46:16,547 INFO: 49428 is random initialized by: cat, 2368
2024-12-09 09:46:16,547 INFO: 49429 is random initialized by: cat, 2368
2024-12-09 09:46:16,547 INFO: 49430 is random initialized by: cat, 2368
2024-12-09 09:46:16,548 INFO: 49431 is random initialized by: cat, 2368
2024-12-09 09:46:16,548 INFO: 49432 is random initialized by: cat, 2368
2024-12-09 09:46:16,548 INFO: 49433 is random initialized by: cat, 2368
2024-12-09 09:46:16,548 INFO: 49434 is random initialized by: cat, 2368
2024-12-09 09:46:16,549 INFO: 49435 is random initialized by: cat, 2368
2024-12-09 09:46:16,549 INFO: 49436 is random initialized by: cat, 2368
2024-12-09 09:46:16,549 INFO: 49437 is random initialized by: cat, 2368
2024-12-09 09:46:16,549 INFO: 49438 is random initialized by: cat, 2368
2024-12-09 09:46:16,549 INFO: 49439 is random initialized by: cat, 2368
2024-12-09 09:46:16,553 INFO: optimizing embedding using lr: 0.001
2024-12-09 09:46:16,568 INFO: optimizing text_encoder (48 LoRAs), using lr: 1e-05
2024-12-09 09:46:16,608 INFO: optimizing unet (128 LoRAs), using lr: 0.0001
2024-12-09 09:46:16,608 INFO: Network [EDLoRA] is created.
2024-12-09 09:46:18,410 INFO: Network: DistributedDataParallel - EDLoRA, with parameters: 1,067,351,979
2024-12-09 09:46:18,410 INFO: EDLoRA(
  (vae): AutoencoderKL(
    (encoder): Encoder(
      (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (down_blocks): ModuleList(
        (0): DownEncoderBlock2D(
          (resnets): ModuleList(
            (0-1): 2 x ResnetBlock2D(
              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (nonlinearity): SiLU()
            )
          )
          (downsamplers): ModuleList(
            (0): Downsample2D(
              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))
            )
          )
        )
        (1): DownEncoderBlock2D(
          (resnets): ModuleList(
            (0): ResnetBlock2D(
              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
              (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (nonlinearity): SiLU()
              (conv_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): ResnetBlock2D(
              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (nonlinearity): SiLU()
            )
          )
          (downsamplers): ModuleList(
            (0): Downsample2D(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
            )
          )
        )
        (2): DownEncoderBlock2D(
          (resnets): ModuleList(
            (0): ResnetBlock2D(
              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (nonlinearity): SiLU()
              (conv_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
            )
            (1): ResnetBlock2D(
              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (nonlinearity): SiLU()
            )
          )
          (downsamplers): ModuleList(
            (0): Downsample2D(
              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2))
            )
          )
        )
        (3): DownEncoderBlock2D(
          (resnets): ModuleList(
            (0-1): 2 x ResnetBlock2D(
              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (nonlinearity): SiLU()
            )
          )
        )
      )
      (mid_block): UNetMidBlock2D(
        (attentions): ModuleList(
          (0): AttentionBlock(
            (group_norm): GroupNorm(32, 512, eps=1e-06, affine=True)
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (proj_attn): Linear(in_features=512, out_features=512, bias=True)
          )
        )
        (resnets): ModuleList(
          (0-1): 2 x ResnetBlock2D(
            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
          )
        )
      )
      (conv_norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)
      (conv_act): SiLU()
      (conv_out): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (decoder): Decoder(
      (conv_in): Conv2d(4, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (up_blocks): ModuleList(
        (0-1): 2 x UpDecoderBlock2D(
          (resnets): ModuleList(
            (0-2): 3 x ResnetBlock2D(
              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
              (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (nonlinearity): SiLU()
            )
          )
          (upsamplers): ModuleList(
            (0): Upsample2D(
              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
        )
        (2): UpDecoderBlock2D(
          (resnets): ModuleList(
            (0): ResnetBlock2D(
              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
              (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (nonlinearity): SiLU()
              (conv_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (1-2): 2 x ResnetBlock2D(
              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (nonlinearity): SiLU()
            )
          )
          (upsamplers): ModuleList(
            (0): Upsample2D(
              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
        )
        (3): UpDecoderBlock2D(
          (resnets): ModuleList(
            (0): ResnetBlock2D(
              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
              (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (nonlinearity): SiLU()
              (conv_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
            )
            (1-2): 2 x ResnetBlock2D(
              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)
              (dropout): Dropout(p=0.0, inplace=False)
              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (nonlinearity): SiLU()
            )
          )
        )
      )
      (mid_block): UNetMidBlock2D(
        (attentions): ModuleList(
          (0): AttentionBlock(
            (group_norm): GroupNorm(32, 512, eps=1e-06, affine=True)
            (query): Linear(in_features=512, out_features=512, bias=True)
            (key): Linear(in_features=512, out_features=512, bias=True)
            (value): Linear(in_features=512, out_features=512, bias=True)
            (proj_attn): Linear(in_features=512, out_features=512, bias=True)
          )
        )
        (resnets): ModuleList(
          (0-1): 2 x ResnetBlock2D(
            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
          )
        )
      )
      (conv_norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)
      (conv_act): SiLU()
      (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))
    (post_quant_conv): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))
  )
  (text_encoder): CLIPTextModel(
    (text_model): CLIPTextTransformer(
      (embeddings): CLIPTextEmbeddings(
        (token_embedding): Embedding(49440, 768)
        (position_embedding): Embedding(77, 768)
      )
      (encoder): CLIPEncoder(
        (layers): ModuleList(
          (0-11): 12 x CLIPEncoderLayer(
            (self_attn): CLIPSdpaAttention(
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): CLIPMLP(
              (activation_fn): QuickGELUActivation()
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
            )
            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
  )
  (unet): UNet2DConditionModel(
    (conv_in): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (time_proj): Timesteps()
    (time_embedding): TimestepEmbedding(
      (linear_1): Linear(in_features=320, out_features=1280, bias=True)
      (act): SiLU()
      (linear_2): Linear(in_features=1280, out_features=1280, bias=True)
    )
    (down_blocks): ModuleList(
      (0): CrossAttnDownBlock2D(
        (attentions): ModuleList(
          (0-1): 2 x Transformer2DModel(
            (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
            (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            (transformer_blocks): ModuleList(
              (0): BasicTransformerBlock(
                (attn1): CrossAttention(
                  (to_q): Linear(in_features=320, out_features=320, bias=False)
                  (to_k): Linear(in_features=320, out_features=320, bias=False)
                  (to_v): Linear(in_features=320, out_features=320, bias=False)
                  (to_out): ModuleList(
                    (0): Linear(in_features=320, out_features=320, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (ff): FeedForward(
                  (net): ModuleList(
                    (0): GEGLU(
                      (proj): Linear(in_features=320, out_features=2560, bias=True)
                    )
                    (1): Dropout(p=0.0, inplace=False)
                    (2): Linear(in_features=1280, out_features=320, bias=True)
                  )
                )
                (attn2): CrossAttention(
                  (to_q): Linear(in_features=320, out_features=320, bias=False)
                  (to_k): Linear(in_features=768, out_features=320, bias=False)
                  (to_v): Linear(in_features=768, out_features=320, bias=False)
                  (to_out): ModuleList(
                    (0): Linear(in_features=320, out_features=320, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
            )
            (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (resnets): ModuleList(
          (0-1): 2 x ResnetBlock2D(
            (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)
            (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)
            (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
          )
        )
        (downsamplers): ModuleList(
          (0): Downsample2D(
            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          )
        )
      )
      (1): CrossAttnDownBlock2D(
        (attentions): ModuleList(
          (0-1): 2 x Transformer2DModel(
            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
            (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            (transformer_blocks): ModuleList(
              (0): BasicTransformerBlock(
                (attn1): CrossAttention(
                  (to_q): Linear(in_features=640, out_features=640, bias=False)
                  (to_k): Linear(in_features=640, out_features=640, bias=False)
                  (to_v): Linear(in_features=640, out_features=640, bias=False)
                  (to_out): ModuleList(
                    (0): Linear(in_features=640, out_features=640, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (ff): FeedForward(
                  (net): ModuleList(
                    (0): GEGLU(
                      (proj): Linear(in_features=640, out_features=5120, bias=True)
                    )
                    (1): Dropout(p=0.0, inplace=False)
                    (2): Linear(in_features=2560, out_features=640, bias=True)
                  )
                )
                (attn2): CrossAttention(
                  (to_q): Linear(in_features=640, out_features=640, bias=False)
                  (to_k): Linear(in_features=768, out_features=640, bias=False)
                  (to_v): Linear(in_features=768, out_features=640, bias=False)
                  (to_out): ModuleList(
                    (0): Linear(in_features=640, out_features=640, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
              )
            )
            (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (resnets): ModuleList(
          (0): ResnetBlock2D(
            (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)
            (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)
            (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
            (conv_shortcut): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))
          )
          (1): ResnetBlock2D(
            (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)
            (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)
            (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
          )
        )
        (downsamplers): ModuleList(
          (0): Downsample2D(
            (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          )
        )
      )
      (2): CrossAttnDownBlock2D(
        (attentions): ModuleList(
          (0-1): 2 x Transformer2DModel(
            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            (transformer_blocks): ModuleList(
              (0): BasicTransformerBlock(
                (attn1): CrossAttention(
                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_out): ModuleList(
                    (0): Linear(in_features=1280, out_features=1280, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (ff): FeedForward(
                  (net): ModuleList(
                    (0): GEGLU(
                      (proj): Linear(in_features=1280, out_features=10240, bias=True)
                    )
                    (1): Dropout(p=0.0, inplace=False)
                    (2): Linear(in_features=5120, out_features=1280, bias=True)
                  )
                )
                (attn2): CrossAttention(
                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_k): Linear(in_features=768, out_features=1280, bias=False)
                  (to_v): Linear(in_features=768, out_features=1280, bias=False)
                  (to_out): ModuleList(
                    (0): Linear(in_features=1280, out_features=1280, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              )
            )
            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (resnets): ModuleList(
          (0): ResnetBlock2D(
            (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)
            (conv1): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
            (conv_shortcut): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))
          )
          (1): ResnetBlock2D(
            (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)
            (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
          )
        )
        (downsamplers): ModuleList(
          (0): Downsample2D(
            (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          )
        )
      )
      (3): DownBlock2D(
        (resnets): ModuleList(
          (0-1): 2 x ResnetBlock2D(
            (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)
            (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
          )
        )
      )
    )
    (up_blocks): ModuleList(
      (0): UpBlock2D(
        (resnets): ModuleList(
          (0-2): 3 x ResnetBlock2D(
            (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)
            (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
            (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (upsamplers): ModuleList(
          (0): Upsample2D(
            (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
      )
      (1): CrossAttnUpBlock2D(
        (attentions): ModuleList(
          (0-2): 3 x Transformer2DModel(
            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
            (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
            (transformer_blocks): ModuleList(
              (0): BasicTransformerBlock(
                (attn1): CrossAttention(
                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_out): ModuleList(
                    (0): Linear(in_features=1280, out_features=1280, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (ff): FeedForward(
                  (net): ModuleList(
                    (0): GEGLU(
                      (proj): Linear(in_features=1280, out_features=10240, bias=True)
                    )
                    (1): Dropout(p=0.0, inplace=False)
                    (2): Linear(in_features=5120, out_features=1280, bias=True)
                  )
                )
                (attn2): CrossAttention(
                  (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                  (to_k): Linear(in_features=768, out_features=1280, bias=False)
                  (to_v): Linear(in_features=768, out_features=1280, bias=False)
                  (to_out): ModuleList(
                    (0): Linear(in_features=1280, out_features=1280, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              )
            )
            (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (resnets): ModuleList(
          (0-1): 2 x ResnetBlock2D(
            (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)
            (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
            (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
          )
          (2): ResnetBlock2D(
            (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)
            (conv1): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)
            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
            (conv_shortcut): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (upsamplers): ModuleList(
          (0): Upsample2D(
            (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
      )
      (2): CrossAttnUpBlock2D(
        (attentions): ModuleList(
          (0-2): 3 x Transformer2DModel(
            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)
            (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
            (transformer_blocks): ModuleList(
              (0): BasicTransformerBlock(
                (attn1): CrossAttention(
                  (to_q): Linear(in_features=640, out_features=640, bias=False)
                  (to_k): Linear(in_features=640, out_features=640, bias=False)
                  (to_v): Linear(in_features=640, out_features=640, bias=False)
                  (to_out): ModuleList(
                    (0): Linear(in_features=640, out_features=640, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (ff): FeedForward(
                  (net): ModuleList(
                    (0): GEGLU(
                      (proj): Linear(in_features=640, out_features=5120, bias=True)
                    )
                    (1): Dropout(p=0.0, inplace=False)
                    (2): Linear(in_features=2560, out_features=640, bias=True)
                  )
                )
                (attn2): CrossAttention(
                  (to_q): Linear(in_features=640, out_features=640, bias=False)
                  (to_k): Linear(in_features=768, out_features=640, bias=False)
                  (to_v): Linear(in_features=768, out_features=640, bias=False)
                  (to_out): ModuleList(
                    (0): Linear(in_features=640, out_features=640, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)
              )
            )
            (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (resnets): ModuleList(
          (0): ResnetBlock2D(
            (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)
            (conv1): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)
            (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
            (conv_shortcut): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
          )
          (1): ResnetBlock2D(
            (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)
            (conv1): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)
            (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
            (conv_shortcut): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))
          )
          (2): ResnetBlock2D(
            (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)
            (conv1): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)
            (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
            (conv_shortcut): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (upsamplers): ModuleList(
          (0): Upsample2D(
            (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
      )
      (3): CrossAttnUpBlock2D(
        (attentions): ModuleList(
          (0-2): 3 x Transformer2DModel(
            (norm): GroupNorm(32, 320, eps=1e-06, affine=True)
            (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
            (transformer_blocks): ModuleList(
              (0): BasicTransformerBlock(
                (attn1): CrossAttention(
                  (to_q): Linear(in_features=320, out_features=320, bias=False)
                  (to_k): Linear(in_features=320, out_features=320, bias=False)
                  (to_v): Linear(in_features=320, out_features=320, bias=False)
                  (to_out): ModuleList(
                    (0): Linear(in_features=320, out_features=320, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (ff): FeedForward(
                  (net): ModuleList(
                    (0): GEGLU(
                      (proj): Linear(in_features=320, out_features=2560, bias=True)
                    )
                    (1): Dropout(p=0.0, inplace=False)
                    (2): Linear(in_features=1280, out_features=320, bias=True)
                  )
                )
                (attn2): CrossAttention(
                  (to_q): Linear(in_features=320, out_features=320, bias=False)
                  (to_k): Linear(in_features=768, out_features=320, bias=False)
                  (to_v): Linear(in_features=768, out_features=320, bias=False)
                  (to_out): ModuleList(
                    (0): Linear(in_features=320, out_features=320, bias=True)
                    (1): Dropout(p=0.0, inplace=False)
                  )
                )
                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
            )
            (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (resnets): ModuleList(
          (0): ResnetBlock2D(
            (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)
            (conv1): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)
            (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
            (conv_shortcut): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))
          )
          (1-2): 2 x ResnetBlock2D(
            (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)
            (conv1): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)
            (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
            (conv_shortcut): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
          )
        )
      )
    )
    (mid_block): UNetMidBlock2DCrossAttn(
      (attentions): ModuleList(
        (0): Transformer2DModel(
          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)
          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
          (transformer_blocks): ModuleList(
            (0): BasicTransformerBlock(
              (attn1): CrossAttention(
                (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                (to_k): Linear(in_features=1280, out_features=1280, bias=False)
                (to_v): Linear(in_features=1280, out_features=1280, bias=False)
                (to_out): ModuleList(
                  (0): Linear(in_features=1280, out_features=1280, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
              (ff): FeedForward(
                (net): ModuleList(
                  (0): GEGLU(
                    (proj): Linear(in_features=1280, out_features=10240, bias=True)
                  )
                  (1): Dropout(p=0.0, inplace=False)
                  (2): Linear(in_features=5120, out_features=1280, bias=True)
                )
              )
              (attn2): CrossAttention(
                (to_q): Linear(in_features=1280, out_features=1280, bias=False)
                (to_k): Linear(in_features=768, out_features=1280, bias=False)
                (to_v): Linear(in_features=768, out_features=1280, bias=False)
                (to_out): ModuleList(
                  (0): Linear(in_features=1280, out_features=1280, bias=True)
                  (1): Dropout(p=0.0, inplace=False)
                )
              )
              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
            )
          )
          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (resnets): ModuleList(
        (0-1): 2 x ResnetBlock2D(
          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)
          (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)
          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (nonlinearity): SiLU()
        )
      )
    )
    (conv_norm_out): GroupNorm(32, 320, eps=1e-05, affine=True)
    (conv_act): SiLU()
    (conv_out): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (text_encoder_lora): ModuleList(
    (0-47): 48 x LoRALinearLayer(
      (down): Linear(in_features=768, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=768, bias=False)
    )
  )
  (unet_lora): ModuleList(
    (0-4): 5 x LoRALinearLayer(
      (down): Linear(in_features=320, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=320, bias=False)
    )
    (5-6): 2 x LoRALinearLayer(
      (down): Linear(in_features=768, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=320, bias=False)
    )
    (7-12): 6 x LoRALinearLayer(
      (down): Linear(in_features=320, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=320, bias=False)
    )
    (13-14): 2 x LoRALinearLayer(
      (down): Linear(in_features=768, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=320, bias=False)
    )
    (15): LoRALinearLayer(
      (down): Linear(in_features=320, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=320, bias=False)
    )
    (16-20): 5 x LoRALinearLayer(
      (down): Linear(in_features=640, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=640, bias=False)
    )
    (21-22): 2 x LoRALinearLayer(
      (down): Linear(in_features=768, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=640, bias=False)
    )
    (23-28): 6 x LoRALinearLayer(
      (down): Linear(in_features=640, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=640, bias=False)
    )
    (29-30): 2 x LoRALinearLayer(
      (down): Linear(in_features=768, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=640, bias=False)
    )
    (31): LoRALinearLayer(
      (down): Linear(in_features=640, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=640, bias=False)
    )
    (32-36): 5 x LoRALinearLayer(
      (down): Linear(in_features=1280, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=1280, bias=False)
    )
    (37-38): 2 x LoRALinearLayer(
      (down): Linear(in_features=768, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=1280, bias=False)
    )
    (39-44): 6 x LoRALinearLayer(
      (down): Linear(in_features=1280, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=1280, bias=False)
    )
    (45-46): 2 x LoRALinearLayer(
      (down): Linear(in_features=768, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=1280, bias=False)
    )
    (47-52): 6 x LoRALinearLayer(
      (down): Linear(in_features=1280, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=1280, bias=False)
    )
    (53-54): 2 x LoRALinearLayer(
      (down): Linear(in_features=768, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=1280, bias=False)
    )
    (55-60): 6 x LoRALinearLayer(
      (down): Linear(in_features=1280, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=1280, bias=False)
    )
    (61-62): 2 x LoRALinearLayer(
      (down): Linear(in_features=768, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=1280, bias=False)
    )
    (63-68): 6 x LoRALinearLayer(
      (down): Linear(in_features=1280, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=1280, bias=False)
    )
    (69-70): 2 x LoRALinearLayer(
      (down): Linear(in_features=768, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=1280, bias=False)
    )
    (71): LoRALinearLayer(
      (down): Linear(in_features=1280, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=1280, bias=False)
    )
    (72-76): 5 x LoRALinearLayer(
      (down): Linear(in_features=640, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=640, bias=False)
    )
    (77-78): 2 x LoRALinearLayer(
      (down): Linear(in_features=768, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=640, bias=False)
    )
    (79-84): 6 x LoRALinearLayer(
      (down): Linear(in_features=640, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=640, bias=False)
    )
    (85-86): 2 x LoRALinearLayer(
      (down): Linear(in_features=768, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=640, bias=False)
    )
    (87-92): 6 x LoRALinearLayer(
      (down): Linear(in_features=640, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=640, bias=False)
    )
    (93-94): 2 x LoRALinearLayer(
      (down): Linear(in_features=768, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=640, bias=False)
    )
    (95): LoRALinearLayer(
      (down): Linear(in_features=640, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=640, bias=False)
    )
    (96-100): 5 x LoRALinearLayer(
      (down): Linear(in_features=320, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=320, bias=False)
    )
    (101-102): 2 x LoRALinearLayer(
      (down): Linear(in_features=768, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=320, bias=False)
    )
    (103-108): 6 x LoRALinearLayer(
      (down): Linear(in_features=320, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=320, bias=False)
    )
    (109-110): 2 x LoRALinearLayer(
      (down): Linear(in_features=768, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=320, bias=False)
    )
    (111-116): 6 x LoRALinearLayer(
      (down): Linear(in_features=320, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=320, bias=False)
    )
    (117-118): 2 x LoRALinearLayer(
      (down): Linear(in_features=768, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=320, bias=False)
    )
    (119): LoRALinearLayer(
      (down): Linear(in_features=320, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=320, bias=False)
    )
    (120-124): 5 x LoRALinearLayer(
      (down): Linear(in_features=1280, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=1280, bias=False)
    )
    (125-126): 2 x LoRALinearLayer(
      (down): Linear(in_features=768, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=1280, bias=False)
    )
    (127): LoRALinearLayer(
      (down): Linear(in_features=1280, out_features=4, bias=False)
      (up): Linear(in_features=4, out_features=1280, bias=False)
    )
  )
)
2024-12-09 09:46:18,432 INFO: Loss [KDELoss] is created.
2024-12-09 09:46:18,432 INFO: Scale learning rate to: 0.00e+00
2024-12-09 09:46:18,433 INFO: Model [EDLoraModel] is created.
2024-12-09 09:46:25,262 INFO: Use cuda prefetch dataloader
2024-12-09 09:46:25,263 INFO: Start training from epoch: 0, iter: 0
2024-12-09 09:46:49,983 INFO: [pet_c..][epoch:  0, iter:      10, lr:(9.910e-04,9.910e-06,9.910e-05,)] [eta: 0:16:42, time (data): 2.472 (0.698)] loss: -3.8276e-01 token_reg: -4.1070e-01 Norm_mean: 3.7737e-01 
2024-12-09 09:47:02,471 INFO: [pet_c..][epoch:  0, iter:      20, lr:(9.810e-04,9.810e-06,9.810e-05,)] [eta: 0:18:22, time (data): 1.860 (0.349)] loss: -3.3606e-01 token_reg: -4.1070e-01 Norm_mean: 3.8912e-01 
2024-12-09 09:47:14,940 INFO: [pet_c..][epoch:  0, iter:      30, lr:(9.710e-04,9.710e-06,9.710e-05,)] [eta: 0:18:48, time (data): 1.656 (0.233)] loss: -1.7711e-01 token_reg: -4.1070e-01 Norm_mean: 4.0009e-01 
2024-12-09 09:47:27,373 INFO: [pet_c..][epoch:  0, iter:      40, lr:(9.610e-04,9.610e-06,9.610e-05,)] [eta: 0:18:55, time (data): 1.553 (0.175)] loss: 6.3966e-01 token_reg: -4.1070e-01 Norm_mean: 4.0958e-01 
2024-12-09 09:47:39,769 INFO: [pet_c..][epoch:  0, iter:      50, lr:(9.510e-04,9.510e-06,9.510e-05,)] [eta: 0:18:53, time (data): 1.490 (0.140)] loss: -3.3106e-01 token_reg: -4.1070e-01 Norm_mean: 4.2010e-01 
2024-12-09 09:47:52,151 INFO: [pet_c..][epoch:  0, iter:      60, lr:(9.410e-04,9.410e-06,9.410e-05,)] [eta: 0:18:48, time (data): 1.448 (0.117)] loss: 7.8204e-01 token_reg: -4.1070e-01 Norm_mean: 4.2809e-01 
2024-12-09 09:48:04,528 INFO: [pet_c..][epoch:  0, iter:      70, lr:(9.310e-04,9.310e-06,9.310e-05,)] [eta: 0:18:41, time (data): 1.418 (0.100)] loss: -2.3078e-01 token_reg: -4.1069e-01 Norm_mean: 4.3729e-01 
2024-12-09 09:48:16,935 INFO: [pet_c..][epoch:  0, iter:      80, lr:(9.210e-04,9.210e-06,9.210e-05,)] [eta: 0:18:33, time (data): 1.396 (0.088)] loss: -3.8632e-01 token_reg: -4.1069e-01 Norm_mean: 4.4643e-01 
2024-12-09 09:48:29,335 INFO: [pet_c..][epoch:  0, iter:      90, lr:(9.110e-04,9.110e-06,9.110e-05,)] [eta: 0:18:23, time (data): 1.378 (0.078)] loss: -3.8699e-01 token_reg: -4.1069e-01 Norm_mean: 4.5340e-01 
2024-12-09 09:48:41,777 INFO: [pet_c..][epoch:  0, iter:     100, lr:(9.010e-04,9.010e-06,9.010e-05,)] [eta: 0:18:14, time (data): 1.365 (0.070)] loss: -4.3737e-03 token_reg: -4.1069e-01 Norm_mean: 4.5970e-01 
2024-12-09 09:48:54,228 INFO: [pet_c..][epoch:  0, iter:     110, lr:(8.910e-04,8.910e-06,8.910e-05,)] [eta: 0:18:04, time (data): 1.354 (0.064)] loss: -1.5587e-01 token_reg: -4.1069e-01 Norm_mean: 4.6572e-01 
2024-12-09 09:49:06,642 INFO: [pet_c..][epoch:  0, iter:     120, lr:(8.810e-04,8.810e-06,8.810e-05,)] [eta: 0:17:53, time (data): 1.345 (0.059)] loss: -2.2007e-01 token_reg: -4.1069e-01 Norm_mean: 4.7105e-01 
2024-12-09 09:49:19,038 INFO: [pet_c..][epoch:  0, iter:     130, lr:(8.710e-04,8.710e-06,8.710e-05,)] [eta: 0:17:42, time (data): 1.337 (0.054)] loss: 5.6684e-02 token_reg: -4.1069e-01 Norm_mean: 4.7649e-01 
2024-12-09 09:49:31,432 INFO: [pet_c..][epoch:  0, iter:     140, lr:(8.610e-04,8.610e-06,8.610e-05,)] [eta: 0:17:31, time (data): 1.330 (0.050)] loss: -3.8894e-01 token_reg: -4.1069e-01 Norm_mean: 4.8235e-01 
2024-12-09 09:49:43,831 INFO: [pet_c..][epoch:  0, iter:     150, lr:(8.510e-04,8.510e-06,8.510e-05,)] [eta: 0:17:20, time (data): 1.324 (0.047)] loss: -3.0952e-01 token_reg: -4.1069e-01 Norm_mean: 4.8810e-01 
2024-12-09 09:49:56,227 INFO: [pet_c..][epoch:  0, iter:     160, lr:(8.410e-04,8.410e-06,8.410e-05,)] [eta: 0:17:08, time (data): 1.318 (0.044)] loss: -3.8675e-01 token_reg: -4.1069e-01 Norm_mean: 4.9258e-01 
2024-12-09 09:50:08,620 INFO: [pet_c..][epoch:  0, iter:     170, lr:(8.310e-04,8.310e-06,8.310e-05,)] [eta: 0:16:57, time (data): 1.314 (0.042)] loss: -3.9341e-01 token_reg: -4.1069e-01 Norm_mean: 4.9545e-01 
2024-12-09 09:50:21,018 INFO: [pet_c..][epoch:  0, iter:     180, lr:(8.210e-04,8.210e-06,8.210e-05,)] [eta: 0:16:45, time (data): 1.310 (0.039)] loss: -3.2512e-01 token_reg: -4.1069e-01 Norm_mean: 4.9801e-01 
2024-12-09 09:50:33,433 INFO: [pet_c..][epoch:  0, iter:     190, lr:(8.110e-04,8.110e-06,8.110e-05,)] [eta: 0:16:33, time (data): 1.306 (0.037)] loss: -3.8906e-01 token_reg: -4.1068e-01 Norm_mean: 5.0152e-01 
2024-12-09 09:50:45,832 INFO: [pet_c..][epoch:  0, iter:     200, lr:(8.010e-04,8.010e-06,8.010e-05,)] [eta: 0:16:21, time (data): 1.303 (0.035)] loss: 5.5512e-01 token_reg: -4.1068e-01 Norm_mean: 5.0518e-01 
2024-12-09 09:50:45,833 INFO: Saving models and training states.
2024-12-09 09:50:45,847 INFO: text_encoder moved: 5.7119096481983433e-05
2024-12-09 09:50:45,884 INFO: unet moved: 0.0007105735026016191
2024-12-09 09:50:58,935 INFO: [pet_c..][epoch:  0, iter:     210, lr:(7.910e-04,7.910e-06,7.910e-05,)] [eta: 0:16:12, time (data): 1.238 (0.001)] loss: 3.4984e-01 token_reg: -4.1068e-01 Norm_mean: 5.0859e-01 
2024-12-09 09:51:11,342 INFO: [pet_c..][epoch:  0, iter:     220, lr:(7.810e-04,7.810e-06,7.810e-05,)] [eta: 0:16:00, time (data): 1.240 (0.001)] loss: 1.0511e+00 token_reg: -4.1068e-01 Norm_mean: 5.1196e-01 
2024-12-09 09:51:23,738 INFO: [pet_c..][epoch:  0, iter:     230, lr:(7.710e-04,7.710e-06,7.710e-05,)] [eta: 0:15:48, time (data): 1.239 (0.001)] loss: 7.2615e-03 token_reg: -4.1068e-01 Norm_mean: 5.1537e-01 
2024-12-09 09:51:36,136 INFO: [pet_c..][epoch:  0, iter:     240, lr:(7.610e-04,7.610e-06,7.610e-05,)] [eta: 0:15:36, time (data): 1.240 (0.001)] loss: 7.2687e-01 token_reg: -4.1068e-01 Norm_mean: 5.1819e-01 
2024-12-09 09:51:48,549 INFO: [pet_c..][epoch:  0, iter:     250, lr:(7.510e-04,7.510e-06,7.510e-05,)] [eta: 0:15:24, time (data): 1.240 (0.001)] loss: 1.1292e+00 token_reg: -4.1068e-01 Norm_mean: 5.2115e-01 
2024-12-09 09:52:00,946 INFO: [pet_c..][epoch:  0, iter:     260, lr:(7.410e-04,7.410e-06,7.410e-05,)] [eta: 0:15:12, time (data): 1.240 (0.001)] loss: 1.0962e-01 token_reg: -4.1068e-01 Norm_mean: 5.2354e-01 
2024-12-09 09:52:13,343 INFO: [pet_c..][epoch:  0, iter:     270, lr:(7.310e-04,7.310e-06,7.310e-05,)] [eta: 0:14:59, time (data): 1.240 (0.001)] loss: 6.8624e-01 token_reg: -4.1068e-01 Norm_mean: 5.2637e-01 
2024-12-09 09:52:25,757 INFO: [pet_c..][epoch:  0, iter:     280, lr:(7.210e-04,7.210e-06,7.210e-05,)] [eta: 0:14:47, time (data): 1.240 (0.001)] loss: -2.4033e-01 token_reg: -4.1068e-01 Norm_mean: 5.2963e-01 
2024-12-09 09:52:38,155 INFO: [pet_c..][epoch:  0, iter:     290, lr:(7.110e-04,7.110e-06,7.110e-05,)] [eta: 0:14:35, time (data): 1.240 (0.001)] loss: 3.3196e-02 token_reg: -4.1068e-01 Norm_mean: 5.3215e-01 
2024-12-09 09:52:50,550 INFO: [pet_c..][epoch:  0, iter:     300, lr:(7.010e-04,7.010e-06,7.010e-05,)] [eta: 0:14:23, time (data): 1.240 (0.001)] loss: 1.3170e-01 token_reg: -4.1068e-01 Norm_mean: 5.3408e-01 
2024-12-09 09:53:02,945 INFO: [pet_c..][epoch:  0, iter:     310, lr:(6.910e-04,6.910e-06,6.910e-05,)] [eta: 0:14:10, time (data): 1.240 (0.001)] loss: -3.3749e-01 token_reg: -4.1068e-01 Norm_mean: 5.3614e-01 
2024-12-09 09:53:15,342 INFO: [pet_c..][epoch:  0, iter:     320, lr:(6.810e-04,6.810e-06,6.810e-05,)] [eta: 0:13:58, time (data): 1.240 (0.001)] loss: -8.6169e-02 token_reg: -4.1068e-01 Norm_mean: 5.3833e-01 
2024-12-09 09:53:27,737 INFO: [pet_c..][epoch:  0, iter:     330, lr:(6.710e-04,6.710e-06,6.710e-05,)] [eta: 0:13:46, time (data): 1.240 (0.001)] loss: -3.8884e-01 token_reg: -4.1068e-01 Norm_mean: 5.4041e-01 
2024-12-09 09:53:40,134 INFO: [pet_c..][epoch:  0, iter:     340, lr:(6.610e-04,6.610e-06,6.610e-05,)] [eta: 0:13:34, time (data): 1.240 (0.001)] loss: 1.1744e+00 token_reg: -4.1068e-01 Norm_mean: 5.4218e-01 
2024-12-09 09:53:52,529 INFO: [pet_c..][epoch:  0, iter:     350, lr:(6.510e-04,6.510e-06,6.510e-05,)] [eta: 0:13:21, time (data): 1.240 (0.001)] loss: 2.4555e-01 token_reg: -4.1068e-01 Norm_mean: 5.4399e-01 
2024-12-09 09:54:04,927 INFO: [pet_c..][epoch:  0, iter:     360, lr:(6.410e-04,6.410e-06,6.410e-05,)] [eta: 0:13:09, time (data): 1.240 (0.001)] loss: -2.0264e-01 token_reg: -4.1068e-01 Norm_mean: 5.4602e-01 
2024-12-09 09:54:17,322 INFO: [pet_c..][epoch:  0, iter:     370, lr:(6.310e-04,6.310e-06,6.310e-05,)] [eta: 0:12:57, time (data): 1.240 (0.001)] loss: -3.8258e-01 token_reg: -4.1068e-01 Norm_mean: 5.4842e-01 
2024-12-09 09:54:29,719 INFO: [pet_c..][epoch:  0, iter:     380, lr:(6.210e-04,6.210e-06,6.210e-05,)] [eta: 0:12:45, time (data): 1.240 (0.001)] loss: -3.7663e-01 token_reg: -4.1068e-01 Norm_mean: 5.5021e-01 
2024-12-09 09:54:42,135 INFO: [pet_c..][epoch:  0, iter:     390, lr:(6.110e-04,6.110e-06,6.110e-05,)] [eta: 0:12:32, time (data): 1.240 (0.001)] loss: 5.4686e-01 token_reg: -4.1068e-01 Norm_mean: 5.5194e-01 
2024-12-09 09:54:54,530 INFO: [pet_c..][epoch:  0, iter:     400, lr:(6.010e-04,6.010e-06,6.010e-05,)] [eta: 0:12:20, time (data): 1.240 (0.001)] loss: -3.5529e-01 token_reg: -4.1068e-01 Norm_mean: 5.5383e-01 
2024-12-09 09:54:54,531 INFO: Saving models and training states.
2024-12-09 09:54:54,546 INFO: text_encoder moved: 7.357003892138891e-05
2024-12-09 09:54:54,581 INFO: unet moved: 0.0009779484125829185
2024-12-09 09:55:07,624 INFO: [pet_c..][epoch:  0, iter:     410, lr:(5.910e-04,5.910e-06,5.910e-05,)] [eta: 0:12:09, time (data): 1.239 (0.000)] loss: -3.3021e-01 token_reg: -4.1068e-01 Norm_mean: 5.5628e-01 
2024-12-09 09:55:20,029 INFO: [pet_c..][epoch:  0, iter:     420, lr:(5.810e-04,5.810e-06,5.810e-05,)] [eta: 0:11:56, time (data): 1.240 (0.001)] loss: 3.2197e-01 token_reg: -4.1067e-01 Norm_mean: 5.5842e-01 
2024-12-09 09:55:32,437 INFO: [pet_c..][epoch:  0, iter:     430, lr:(5.710e-04,5.710e-06,5.710e-05,)] [eta: 0:11:44, time (data): 1.240 (0.000)] loss: -3.7756e-01 token_reg: -4.1067e-01 Norm_mean: 5.6038e-01 
2024-12-09 09:55:44,838 INFO: [pet_c..][epoch:  0, iter:     440, lr:(5.610e-04,5.610e-06,5.610e-05,)] [eta: 0:11:32, time (data): 1.240 (0.000)] loss: -3.5014e-01 token_reg: -4.1067e-01 Norm_mean: 5.6209e-01 
2024-12-09 09:55:57,249 INFO: [pet_c..][epoch:  0, iter:     450, lr:(5.510e-04,5.510e-06,5.510e-05,)] [eta: 0:11:19, time (data): 1.240 (0.000)] loss: -3.5993e-01 token_reg: -4.1067e-01 Norm_mean: 5.6375e-01 
2024-12-09 09:56:09,647 INFO: [pet_c..][epoch:  0, iter:     460, lr:(5.410e-04,5.410e-06,5.410e-05,)] [eta: 0:11:07, time (data): 1.240 (0.000)] loss: -3.2815e-01 token_reg: -4.1067e-01 Norm_mean: 5.6558e-01 
2024-12-09 09:56:22,042 INFO: [pet_c..][epoch:  0, iter:     470, lr:(5.310e-04,5.310e-06,5.310e-05,)] [eta: 0:10:55, time (data): 1.240 (0.000)] loss: -2.0610e-01 token_reg: -4.1067e-01 Norm_mean: 5.6774e-01 
2024-12-09 09:56:34,438 INFO: [pet_c..][epoch:  0, iter:     480, lr:(5.210e-04,5.210e-06,5.210e-05,)] [eta: 0:10:42, time (data): 1.240 (0.000)] loss: -3.5842e-01 token_reg: -4.1067e-01 Norm_mean: 5.7022e-01 
2024-12-09 09:56:46,835 INFO: [pet_c..][epoch:  0, iter:     490, lr:(5.110e-04,5.110e-06,5.110e-05,)] [eta: 0:10:30, time (data): 1.240 (0.000)] loss: -2.0009e-01 token_reg: -4.1067e-01 Norm_mean: 5.7273e-01 
2024-12-09 09:57:00,566 INFO: [pet_c..][epoch:  0, iter:     500, lr:(5.010e-04,5.010e-06,5.010e-05,)] [eta: 0:10:19, time (data): 1.253 (0.014)] loss: 5.0874e-01 token_reg: -4.1067e-01 Norm_mean: 5.7492e-01 
2024-12-09 09:57:19,764 INFO: [pet_c..][epoch:  1, iter:     510, lr:(4.910e-04,4.910e-06,4.910e-05,)] [eta: 0:10:13, time (data): 1.315 (0.076)] loss: 7.3327e-01 token_reg: -4.1067e-01 Norm_mean: 5.7654e-01 
2024-12-09 09:57:32,206 INFO: [pet_c..][epoch:  1, iter:     520, lr:(4.810e-04,4.810e-06,4.810e-05,)] [eta: 0:10:00, time (data): 1.309 (0.070)] loss: 1.6523e+00 token_reg: -4.1067e-01 Norm_mean: 5.7799e-01 
2024-12-09 09:57:44,704 INFO: [pet_c..][epoch:  1, iter:     530, lr:(4.710e-04,4.710e-06,4.710e-05,)] [eta: 0:09:48, time (data): 1.304 (0.064)] loss: 7.5690e-02 token_reg: -4.1067e-01 Norm_mean: 5.7948e-01 
2024-12-09 09:57:57,232 INFO: [pet_c..][epoch:  1, iter:     540, lr:(4.610e-04,4.610e-06,4.610e-05,)] [eta: 0:09:35, time (data): 1.301 (0.060)] loss: 5.5067e-01 token_reg: -4.1067e-01 Norm_mean: 5.8080e-01 
2024-12-09 09:58:09,627 INFO: [pet_c..][epoch:  1, iter:     550, lr:(4.510e-04,4.510e-06,4.510e-05,)] [eta: 0:09:22, time (data): 1.297 (0.056)] loss: 7.5559e-01 token_reg: -4.1067e-01 Norm_mean: 5.8215e-01 
2024-12-09 09:58:22,020 INFO: [pet_c..][epoch:  1, iter:     560, lr:(4.410e-04,4.410e-06,4.410e-05,)] [eta: 0:09:10, time (data): 1.293 (0.052)] loss: 5.5342e-01 token_reg: -4.1067e-01 Norm_mean: 5.8343e-01 
2024-12-09 09:58:34,416 INFO: [pet_c..][epoch:  1, iter:     570, lr:(4.310e-04,4.310e-06,4.310e-05,)] [eta: 0:08:57, time (data): 1.290 (0.049)] loss: -3.8613e-01 token_reg: -4.1067e-01 Norm_mean: 5.8468e-01 
2024-12-09 09:58:46,814 INFO: [pet_c..][epoch:  1, iter:     580, lr:(4.210e-04,4.210e-06,4.210e-05,)] [eta: 0:08:44, time (data): 1.287 (0.046)] loss: -2.0755e-01 token_reg: -4.1067e-01 Norm_mean: 5.8598e-01 
2024-12-09 09:58:59,212 INFO: [pet_c..][epoch:  1, iter:     590, lr:(4.110e-04,4.110e-06,4.110e-05,)] [eta: 0:08:32, time (data): 1.284 (0.044)] loss: 3.7940e-01 token_reg: -4.1067e-01 Norm_mean: 5.8703e-01 
2024-12-09 09:59:11,625 INFO: [pet_c..][epoch:  1, iter:     600, lr:(4.010e-04,4.010e-06,4.010e-05,)] [eta: 0:08:19, time (data): 1.282 (0.042)] loss: 6.1883e-01 token_reg: -4.1067e-01 Norm_mean: 5.8804e-01 
2024-12-09 09:59:11,626 INFO: Saving models and training states.
2024-12-09 09:59:11,641 INFO: text_encoder moved: 8.436946579119346e-05
2024-12-09 09:59:11,688 INFO: unet moved: 0.0011739349552044587
2024-12-09 09:59:24,764 INFO: [pet_c..][epoch:  1, iter:     610, lr:(3.910e-04,3.910e-06,3.910e-05,)] [eta: 0:08:07, time (data): 1.242 (0.001)] loss: -3.8195e-01 token_reg: -4.1067e-01 Norm_mean: 5.8923e-01 
2024-12-09 09:59:37,160 INFO: [pet_c..][epoch:  1, iter:     620, lr:(3.810e-04,3.810e-06,3.810e-05,)] [eta: 0:07:55, time (data): 1.240 (0.001)] loss: 6.2104e-01 token_reg: -4.1067e-01 Norm_mean: 5.9012e-01 
2024-12-09 09:59:49,556 INFO: [pet_c..][epoch:  1, iter:     630, lr:(3.710e-04,3.710e-06,3.710e-05,)] [eta: 0:07:42, time (data): 1.240 (0.000)] loss: -6.5116e-02 token_reg: -4.1067e-01 Norm_mean: 5.9110e-01 
2024-12-09 10:00:01,950 INFO: [pet_c..][epoch:  1, iter:     640, lr:(3.610e-04,3.610e-06,3.610e-05,)] [eta: 0:07:29, time (data): 1.240 (0.001)] loss: 2.5987e-01 token_reg: -4.1067e-01 Norm_mean: 5.9209e-01 
2024-12-09 10:00:14,349 INFO: [pet_c..][epoch:  1, iter:     650, lr:(3.510e-04,3.510e-06,3.510e-05,)] [eta: 0:07:17, time (data): 1.240 (0.001)] loss: 1.4778e+00 token_reg: -4.1067e-01 Norm_mean: 5.9298e-01 
2024-12-09 10:00:26,764 INFO: [pet_c..][epoch:  1, iter:     660, lr:(3.410e-04,3.410e-06,3.410e-05,)] [eta: 0:07:04, time (data): 1.240 (0.001)] loss: -2.6845e-01 token_reg: -4.1067e-01 Norm_mean: 5.9395e-01 
2024-12-09 10:00:39,159 INFO: [pet_c..][epoch:  1, iter:     670, lr:(3.310e-04,3.310e-06,3.310e-05,)] [eta: 0:06:52, time (data): 1.240 (0.001)] loss: -3.9801e-01 token_reg: -4.1067e-01 Norm_mean: 5.9474e-01 
2024-12-09 10:00:51,555 INFO: [pet_c..][epoch:  1, iter:     680, lr:(3.210e-04,3.210e-06,3.210e-05,)] [eta: 0:06:39, time (data): 1.240 (0.001)] loss: 7.3161e-01 token_reg: -4.1067e-01 Norm_mean: 5.9529e-01 
2024-12-09 10:01:03,953 INFO: [pet_c..][epoch:  1, iter:     690, lr:(3.110e-04,3.110e-06,3.110e-05,)] [eta: 0:06:26, time (data): 1.240 (0.001)] loss: -1.8858e-01 token_reg: -4.1067e-01 Norm_mean: 5.9588e-01 
2024-12-09 10:01:16,366 INFO: [pet_c..][epoch:  1, iter:     700, lr:(3.010e-04,3.010e-06,3.010e-05,)] [eta: 0:06:14, time (data): 1.240 (0.001)] loss: -2.5082e-01 token_reg: -4.1067e-01 Norm_mean: 5.9649e-01 
2024-12-09 10:01:28,763 INFO: [pet_c..][epoch:  1, iter:     710, lr:(2.910e-04,2.910e-06,2.910e-05,)] [eta: 0:06:01, time (data): 1.240 (0.001)] loss: 1.9475e-02 token_reg: -4.1067e-01 Norm_mean: 5.9703e-01 
2024-12-09 10:01:41,160 INFO: [pet_c..][epoch:  1, iter:     720, lr:(2.810e-04,2.810e-06,2.810e-05,)] [eta: 0:05:49, time (data): 1.240 (0.001)] loss: 1.1887e-01 token_reg: -4.1067e-01 Norm_mean: 5.9750e-01 
2024-12-09 10:01:53,555 INFO: [pet_c..][epoch:  1, iter:     730, lr:(2.710e-04,2.710e-06,2.710e-05,)] [eta: 0:05:36, time (data): 1.240 (0.001)] loss: -3.7583e-01 token_reg: -4.1067e-01 Norm_mean: 5.9789e-01 
2024-12-09 10:02:05,951 INFO: [pet_c..][epoch:  1, iter:     740, lr:(2.610e-04,2.610e-06,2.610e-05,)] [eta: 0:05:24, time (data): 1.240 (0.001)] loss: -3.2161e-01 token_reg: -4.1067e-01 Norm_mean: 5.9824e-01 
2024-12-09 10:02:18,348 INFO: [pet_c..][epoch:  1, iter:     750, lr:(2.510e-04,2.510e-06,2.510e-05,)] [eta: 0:05:11, time (data): 1.240 (0.001)] loss: -2.8001e-01 token_reg: -4.1067e-01 Norm_mean: 5.9855e-01 
2024-12-09 10:02:30,744 INFO: [pet_c..][epoch:  1, iter:     760, lr:(2.410e-04,2.410e-06,2.410e-05,)] [eta: 0:04:58, time (data): 1.240 (0.001)] loss: 1.5656e+00 token_reg: -4.1067e-01 Norm_mean: 5.9877e-01 
2024-12-09 10:02:43,140 INFO: [pet_c..][epoch:  1, iter:     770, lr:(2.310e-04,2.310e-06,2.310e-05,)] [eta: 0:04:46, time (data): 1.240 (0.001)] loss: -3.2709e-01 token_reg: -4.1067e-01 Norm_mean: 5.9905e-01 
2024-12-09 10:02:55,535 INFO: [pet_c..][epoch:  1, iter:     780, lr:(2.210e-04,2.210e-06,2.210e-05,)] [eta: 0:04:33, time (data): 1.240 (0.001)] loss: -3.6879e-01 token_reg: -4.1067e-01 Norm_mean: 5.9930e-01 
2024-12-09 10:03:07,930 INFO: [pet_c..][epoch:  1, iter:     790, lr:(2.110e-04,2.110e-06,2.110e-05,)] [eta: 0:04:21, time (data): 1.240 (0.001)] loss: -2.7111e-01 token_reg: -4.1067e-01 Norm_mean: 5.9949e-01 
2024-12-09 10:03:20,330 INFO: [pet_c..][epoch:  1, iter:     800, lr:(2.010e-04,2.010e-06,2.010e-05,)] [eta: 0:04:08, time (data): 1.240 (0.001)] loss: -9.5563e-02 token_reg: -4.1067e-01 Norm_mean: 5.9956e-01 
2024-12-09 10:03:20,331 INFO: Saving models and training states.
2024-12-09 10:03:20,343 INFO: text_encoder moved: 9.113847136177355e-05
2024-12-09 10:03:20,377 INFO: unet moved: 0.0012596902274708555
2024-12-09 10:03:33,443 INFO: [pet_c..][epoch:  1, iter:     810, lr:(1.910e-04,1.910e-06,1.910e-05,)] [eta: 0:03:56, time (data): 1.241 (0.001)] loss: 1.7643e-01 token_reg: -4.1067e-01 Norm_mean: 5.9968e-01 
2024-12-09 10:03:45,839 INFO: [pet_c..][epoch:  1, iter:     820, lr:(1.810e-04,1.810e-06,1.810e-05,)] [eta: 0:03:43, time (data): 1.240 (0.001)] loss: -3.9473e-01 token_reg: -4.1067e-01 Norm_mean: 5.9992e-01 
2024-12-09 10:03:58,234 INFO: [pet_c..][epoch:  1, iter:     830, lr:(1.710e-04,1.710e-06,1.710e-05,)] [eta: 0:03:31, time (data): 1.240 (0.001)] loss: 1.3130e-01 token_reg: -4.1067e-01 Norm_mean: 6.0010e-01 
2024-12-09 10:04:10,631 INFO: [pet_c..][epoch:  1, iter:     840, lr:(1.610e-04,1.610e-06,1.610e-05,)] [eta: 0:03:18, time (data): 1.240 (0.001)] loss: -2.7590e-01 token_reg: -4.1067e-01 Norm_mean: 6.0028e-01 
2024-12-09 10:04:23,048 INFO: [pet_c..][epoch:  1, iter:     850, lr:(1.510e-04,1.510e-06,1.510e-05,)] [eta: 0:03:06, time (data): 1.240 (0.001)] loss: 1.9948e+00 token_reg: -4.1067e-01 Norm_mean: 6.0044e-01 
2024-12-09 10:04:35,445 INFO: [pet_c..][epoch:  1, iter:     860, lr:(1.410e-04,1.410e-06,1.410e-05,)] [eta: 0:02:53, time (data): 1.240 (0.001)] loss: -3.0272e-01 token_reg: -4.1067e-01 Norm_mean: 6.0060e-01 
2024-12-09 10:04:47,859 INFO: [pet_c..][epoch:  1, iter:     870, lr:(1.310e-04,1.310e-06,1.310e-05,)] [eta: 0:02:41, time (data): 1.240 (0.001)] loss: -1.8701e-01 token_reg: -4.1067e-01 Norm_mean: 6.0071e-01 
2024-12-09 10:05:00,257 INFO: [pet_c..][epoch:  1, iter:     880, lr:(1.210e-04,1.210e-06,1.210e-05,)] [eta: 0:02:28, time (data): 1.240 (0.001)] loss: -7.4963e-02 token_reg: -4.1067e-01 Norm_mean: 6.0081e-01 
2024-12-09 10:05:12,651 INFO: [pet_c..][epoch:  1, iter:     890, lr:(1.110e-04,1.110e-06,1.110e-05,)] [eta: 0:02:16, time (data): 1.240 (0.001)] loss: 1.4603e+00 token_reg: -4.1067e-01 Norm_mean: 6.0090e-01 
2024-12-09 10:05:25,046 INFO: [pet_c..][epoch:  1, iter:     900, lr:(1.010e-04,1.010e-06,1.010e-05,)] [eta: 0:02:03, time (data): 1.240 (0.001)] loss: 1.1375e+00 token_reg: -4.1067e-01 Norm_mean: 6.0098e-01 
2024-12-09 10:05:37,444 INFO: [pet_c..][epoch:  1, iter:     910, lr:(9.100e-05,9.100e-07,9.100e-06,)] [eta: 0:01:51, time (data): 1.240 (0.001)] loss: 9.2466e-02 token_reg: -4.1067e-01 Norm_mean: 6.0102e-01 
2024-12-09 10:05:49,839 INFO: [pet_c..][epoch:  1, iter:     920, lr:(8.100e-05,8.100e-07,8.100e-06,)] [eta: 0:01:38, time (data): 1.240 (0.001)] loss: -2.3238e-01 token_reg: -4.1067e-01 Norm_mean: 6.0106e-01 
2024-12-09 10:06:02,236 INFO: [pet_c..][epoch:  1, iter:     930, lr:(7.100e-05,7.100e-07,7.100e-06,)] [eta: 0:01:26, time (data): 1.240 (0.001)] loss: 8.5853e-01 token_reg: -4.1067e-01 Norm_mean: 6.0107e-01 
2024-12-09 10:06:14,631 INFO: [pet_c..][epoch:  1, iter:     940, lr:(6.100e-05,6.100e-07,6.100e-06,)] [eta: 0:01:13, time (data): 1.240 (0.001)] loss: 1.6741e-02 token_reg: -4.1067e-01 Norm_mean: 6.0108e-01 
2024-12-09 10:06:27,029 INFO: [pet_c..][epoch:  1, iter:     950, lr:(5.100e-05,5.100e-07,5.100e-06,)] [eta: 0:01:01, time (data): 1.240 (0.001)] loss: -1.1896e-01 token_reg: -4.1067e-01 Norm_mean: 6.0109e-01 
2024-12-09 10:06:39,424 INFO: [pet_c..][epoch:  1, iter:     960, lr:(4.100e-05,4.100e-07,4.100e-06,)] [eta: 0:00:48, time (data): 1.240 (0.001)] loss: -3.9777e-01 token_reg: -4.1067e-01 Norm_mean: 6.0109e-01 
2024-12-09 10:06:51,820 INFO: [pet_c..][epoch:  1, iter:     970, lr:(3.100e-05,3.100e-07,3.100e-06,)] [eta: 0:00:36, time (data): 1.240 (0.001)] loss: 2.9538e-01 token_reg: -4.1067e-01 Norm_mean: 6.0109e-01 
2024-12-09 10:07:04,216 INFO: [pet_c..][epoch:  1, iter:     980, lr:(2.100e-05,2.100e-07,2.100e-06,)] [eta: 0:00:23, time (data): 1.240 (0.001)] loss: 1.8827e+00 token_reg: -4.1067e-01 Norm_mean: 6.0109e-01 
2024-12-09 10:07:16,611 INFO: [pet_c..][epoch:  1, iter:     990, lr:(1.100e-05,1.100e-07,1.100e-06,)] [eta: 0:00:11, time (data): 1.240 (0.001)] loss: -1.4350e-01 token_reg: -4.1067e-01 Norm_mean: 6.0108e-01 
2024-12-09 10:07:30,336 INFO: [pet_c..][epoch:  1, iter:   1,000, lr:(1.000e-06,1.000e-08,1.000e-07,)] [eta: -1 day, 23:59:59, time (data): 1.246 (0.007)] loss: -9.3451e-02 token_reg: -4.1067e-01 Norm_mean: 6.0108e-01 
2024-12-09 10:07:30,338 INFO: Saving models and training states.
2024-12-09 10:07:30,350 INFO: text_encoder moved: 9.34710346882639e-05
2024-12-09 10:07:30,385 INFO: unet moved: 0.0012892427189399314
2024-12-09 10:08:17,101 INFO: End of training. Time consumed: 0:21:51
2024-12-09 10:08:17,101 INFO: Save the latest model.
2024-12-09 10:08:17,118 INFO: text_encoder moved: 9.34710346882639e-05
2024-12-09 10:08:17,167 INFO: unet moved: 0.0012892427189399314
