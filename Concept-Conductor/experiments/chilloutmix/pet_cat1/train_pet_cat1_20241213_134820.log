2024-12-13 13:48:20,881 INFO: Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: fp16

2024-12-13 13:48:20,882 INFO: 
  name: pet_cat1
  manual_seed: 0
  mixed_precision: fp16
  gradient_accumulation_steps: 1
  datasets:[
    train:[
      name: LoraDataset
      concept_list: Data/jsons/pet_cat1.json
      use_caption: True
      use_mask: True
      instance_transform: [{'type': 'HumanResizeCropFinalV3', 'size': 512, 'crop_p': 0.5}, {'type': 'ToTensor'}, {'type': 'Normalize', 'mean': [0.5], 'std': [0.5]}, {'type': 'ShuffleCaption', 'keep_token_num': 1}, {'type': 'EnhanceText', 'enhance_type': 'object'}]
      replace_mapping:[
        <TOK>: <pet_cat1_1> <pet_cat1_2>
      ]
      batch_size_per_gpu: 2
      dataset_enlarge_ratio: 500
    ]
    val_vis:[
      name: PromptDataset
      prompts: Data/val.txt
      num_samples_per_prompt: 1
      latent_size: [4, 64, 64]
      replace_mapping:[
        <TOK>: <pet_cat1_1> <pet_cat1_2>
      ]
      batch_size_per_gpu: 4
    ]
  ]
  models:[
    pretrained_path: experiments/pretrained_models/chilloutmix
    enable_edlora: True
    finetune_cfg:[
      text_embedding:[
        enable_tuning: True
        lr: 0.001
      ]
      text_encoder:[
        enable_tuning: True
        lora_cfg:[
          rank: 4
          alpha: 1
          where: CLIPAttention
        ]
        lr: 1e-05
      ]
      unet:[
        enable_tuning: True
        lora_cfg:[
          rank: 4
          alpha: 1
          where: Attention
        ]
        lr: 0.0001
      ]
    ]
    new_concept_token: <pet_cat1_1>+<pet_cat1_2>
    noise_offset: 0.01
    initializer_token: <rand-0.013>+cat
    attn_reg_weight: 0.01
    reg_full_identity: False
    use_mask_loss: True
    gradient_checkpoint: False
    enable_xformers: True
  ]
  path:[
    pretrain_network: None
    experiments_root: /home/iampoo/dlcv2024/final/Concept-Conductor/experiments/pet_cat1
    models: /home/iampoo/dlcv2024/final/Concept-Conductor/experiments/pet_cat1/models
    log: /home/iampoo/dlcv2024/final/Concept-Conductor/experiments/pet_cat1
    visualization: /home/iampoo/dlcv2024/final/Concept-Conductor/experiments/pet_cat1/visualization
  ]
  train:[
    optim_g:[
      type: AdamW
      lr: 0.0
      weight_decay: 0.01
      betas: [0.9, 0.999]
    ]
    unet_kv_drop_rate: 0
    scheduler: linear
    emb_norm_threshold: 0.55
  ]
  val:[
    val_during_save: True
    compose_visualize: True
    alpha_list: [0, 0.7, 1.0]
    sample:[
      num_inference_steps: 50
      guidance_scale: 7.5
    ]
  ]
  logger:[
    print_freq: 10
    save_checkpoint_freq: 10000.0
  ]
  is_train: True

2024-12-13 13:48:22,468 INFO: <pet_cat1_1> (49408-49423) is random initialized by: <rand-0.013>
2024-12-13 13:48:22,816 INFO: <pet_cat1_2> (49424-49439) is random initialized by existing token (cat): 2368
2024-12-13 13:48:22,820 INFO: optimizing embedding using lr: 0.001
2024-12-13 13:48:22,820 INFO: optimizing text_encoder (0 LoRAs), using lr: 1e-05
2024-12-13 13:48:22,843 INFO: optimizing unet (128 LoRAs), using lr: 0.0001
2024-12-13 13:48:23,333 INFO: ***** Running training *****
2024-12-13 13:48:23,334 INFO:   Num examples = 2500
2024-12-13 13:48:23,334 INFO:   Instantaneous batch size per device = 2
2024-12-13 13:48:23,334 INFO:   Total train batch size (w. parallel, distributed & accumulation) = 2
2024-12-13 13:48:23,334 INFO:   Total optimization steps = 1250.0
2024-12-13 13:48:28,484 INFO: [pet_c..][Iter:      10, lr:(9.920e-04,9.920e-06,9.920e-05,)] [eta: 0:09:40] loss: 4.1010e-02 Norm_mean: 3.8392e-01 
2024-12-13 13:48:33,077 INFO: [pet_c..][Iter:      20, lr:(9.840e-04,9.840e-06,9.840e-05,)] [eta: 0:09:30] loss: 1.9414e-01 Norm_mean: 3.9732e-01 
2024-12-13 13:48:37,368 INFO: [pet_c..][Iter:      30, lr:(9.760e-04,9.760e-06,9.760e-05,)] [eta: 0:09:11] loss: 2.3368e-01 Norm_mean: 4.0881e-01 
2024-12-13 13:48:41,774 INFO: [pet_c..][Iter:      40, lr:(9.680e-04,9.680e-06,9.680e-05,)] [eta: 0:09:03] loss: 7.5654e-01 Norm_mean: 4.1864e-01 
2024-12-13 13:48:46,329 INFO: [pet_c..][Iter:      50, lr:(9.600e-04,9.600e-06,9.600e-05,)] [eta: 0:09:00] loss: 7.2754e-02 Norm_mean: 4.2848e-01 
2024-12-13 13:48:50,584 INFO: [pet_c..][Iter:      60, lr:(9.520e-04,9.520e-06,9.520e-05,)] [eta: 0:08:51] loss: 6.1256e-01 Norm_mean: 4.3779e-01 
2024-12-13 13:48:55,028 INFO: [pet_c..][Iter:      70, lr:(9.440e-04,9.440e-06,9.440e-05,)] [eta: 0:08:46] loss: 7.1058e-01 Norm_mean: 4.4634e-01 
2024-12-13 13:48:59,500 INFO: [pet_c..][Iter:      80, lr:(9.360e-04,9.360e-06,9.360e-05,)] [eta: 0:08:41] loss: 1.7450e-01 Norm_mean: 4.5414e-01 
2024-12-13 13:49:03,984 INFO: [pet_c..][Iter:      90, lr:(9.280e-04,9.280e-06,9.280e-05,)] [eta: 0:08:37] loss: 1.9049e-02 Norm_mean: 4.6080e-01 
2024-12-13 13:49:08,178 INFO: [pet_c..][Iter:     100, lr:(9.200e-04,9.200e-06,9.200e-05,)] [eta: 0:08:30] loss: 2.2543e-01 Norm_mean: 4.6666e-01 
2024-12-13 13:49:12,741 INFO: [pet_c..][Iter:     110, lr:(9.120e-04,9.120e-06,9.120e-05,)] [eta: 0:08:26] loss: 4.0403e-01 Norm_mean: 4.7264e-01 
2024-12-13 13:49:17,218 INFO: [pet_c..][Iter:     120, lr:(9.040e-04,9.040e-06,9.040e-05,)] [eta: 0:08:22] loss: 6.8217e-01 Norm_mean: 4.7813e-01 
2024-12-13 13:49:21,784 INFO: [pet_c..][Iter:     130, lr:(8.960e-04,8.960e-06,8.960e-05,)] [eta: 0:08:19] loss: 3.4387e-01 Norm_mean: 4.8396e-01 
2024-12-13 13:49:26,253 INFO: [pet_c..][Iter:     140, lr:(8.880e-04,8.880e-06,8.880e-05,)] [eta: 0:08:14] loss: 1.3866e+00 Norm_mean: 4.8943e-01 
2024-12-13 13:49:30,572 INFO: [pet_c..][Iter:     150, lr:(8.800e-04,8.800e-06,8.800e-05,)] [eta: 0:08:09] loss: 1.1761e-01 Norm_mean: 4.9472e-01 
2024-12-13 13:49:35,145 INFO: [pet_c..][Iter:     160, lr:(8.720e-04,8.720e-06,8.720e-05,)] [eta: 0:08:05] loss: 8.2085e-01 Norm_mean: 4.9971e-01 
2024-12-13 13:49:39,446 INFO: [pet_c..][Iter:     170, lr:(8.640e-04,8.640e-06,8.640e-05,)] [eta: 0:08:00] loss: 6.3221e-02 Norm_mean: 5.0378e-01 
2024-12-13 13:49:43,641 INFO: [pet_c..][Iter:     180, lr:(8.560e-04,8.560e-06,8.560e-05,)] [eta: 0:07:54] loss: 4.9868e-02 Norm_mean: 5.0829e-01 
2024-12-13 13:49:48,044 INFO: [pet_c..][Iter:     190, lr:(8.480e-04,8.480e-06,8.480e-05,)] [eta: 0:07:49] loss: 1.1287e-01 Norm_mean: 5.1282e-01 
2024-12-13 13:49:52,597 INFO: [pet_c..][Iter:     200, lr:(8.400e-04,8.400e-06,8.400e-05,)] [eta: 0:07:45] loss: 6.5900e-01 Norm_mean: 5.1732e-01 
2024-12-13 13:49:57,126 INFO: [pet_c..][Iter:     210, lr:(8.320e-04,8.320e-06,8.320e-05,)] [eta: 0:07:41] loss: 5.9721e-01 Norm_mean: 5.2228e-01 
2024-12-13 13:50:01,643 INFO: [pet_c..][Iter:     220, lr:(8.240e-04,8.240e-06,8.240e-05,)] [eta: 0:07:37] loss: 1.0357e+00 Norm_mean: 5.2744e-01 
2024-12-13 13:50:06,120 INFO: [pet_c..][Iter:     230, lr:(8.160e-04,8.160e-06,8.160e-05,)] [eta: 0:07:33] loss: 2.5456e-01 Norm_mean: 5.3210e-01 
2024-12-13 13:50:10,412 INFO: [pet_c..][Iter:     240, lr:(8.080e-04,8.080e-06,8.080e-05,)] [eta: 0:07:28] loss: 1.0020e+00 Norm_mean: 5.3604e-01 
2024-12-13 13:50:14,902 INFO: [pet_c..][Iter:     250, lr:(8.000e-04,8.000e-06,8.000e-05,)] [eta: 0:07:24] loss: 1.0584e+00 Norm_mean: 5.3967e-01 
2024-12-13 13:50:19,276 INFO: [pet_c..][Iter:     260, lr:(7.920e-04,7.920e-06,7.920e-05,)] [eta: 0:07:19] loss: 2.9880e-01 Norm_mean: 5.4281e-01 
2024-12-13 13:50:23,682 INFO: [pet_c..][Iter:     270, lr:(7.840e-04,7.840e-06,7.840e-05,)] [eta: 0:07:14] loss: 5.7543e-01 Norm_mean: 5.4576e-01 
2024-12-13 13:50:28,263 INFO: [pet_c..][Iter:     280, lr:(7.760e-04,7.760e-06,7.760e-05,)] [eta: 0:07:10] loss: 4.2172e-01 Norm_mean: 5.4897e-01 
2024-12-13 13:50:32,715 INFO: [pet_c..][Iter:     290, lr:(7.680e-04,7.680e-06,7.680e-05,)] [eta: 0:07:06] loss: 4.7467e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:50:37,143 INFO: [pet_c..][Iter:     300, lr:(7.600e-04,7.600e-06,7.600e-05,)] [eta: 0:07:01] loss: 3.2116e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:50:41,017 INFO: [pet_c..][Iter:     310, lr:(7.520e-04,7.520e-06,7.520e-05,)] [eta: 0:06:55] loss: 8.0322e-02 Norm_mean: 5.5028e-01 
2024-12-13 13:50:45,299 INFO: [pet_c..][Iter:     320, lr:(7.440e-04,7.440e-06,7.440e-05,)] [eta: 0:06:50] loss: 3.9928e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:50:49,708 INFO: [pet_c..][Iter:     330, lr:(7.360e-04,7.360e-06,7.360e-05,)] [eta: 0:06:46] loss: 1.5839e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:50:54,340 INFO: [pet_c..][Iter:     340, lr:(7.280e-04,7.280e-06,7.280e-05,)] [eta: 0:06:42] loss: 7.8603e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:50:58,864 INFO: [pet_c..][Iter:     350, lr:(7.200e-04,7.200e-06,7.200e-05,)] [eta: 0:06:38] loss: 3.6196e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:51:03,193 INFO: [pet_c..][Iter:     360, lr:(7.120e-04,7.120e-06,7.120e-05,)] [eta: 0:06:33] loss: 4.8101e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:51:07,445 INFO: [pet_c..][Iter:     370, lr:(7.040e-04,7.040e-06,7.040e-05,)] [eta: 0:06:28] loss: 4.4960e-02 Norm_mean: 5.5028e-01 
2024-12-13 13:51:11,739 INFO: [pet_c..][Iter:     380, lr:(6.960e-04,6.960e-06,6.960e-05,)] [eta: 0:06:24] loss: 2.1479e-02 Norm_mean: 5.5028e-01 
2024-12-13 13:51:16,278 INFO: [pet_c..][Iter:     390, lr:(6.880e-04,6.880e-06,6.880e-05,)] [eta: 0:06:19] loss: 9.3459e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:51:20,488 INFO: [pet_c..][Iter:     400, lr:(6.800e-04,6.800e-06,6.800e-05,)] [eta: 0:06:15] loss: 1.2041e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:51:24,968 INFO: [pet_c..][Iter:     410, lr:(6.720e-04,6.720e-06,6.720e-05,)] [eta: 0:06:10] loss: 5.5561e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:51:29,202 INFO: [pet_c..][Iter:     420, lr:(6.640e-04,6.640e-06,6.640e-05,)] [eta: 0:06:05] loss: 3.7386e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:51:33,740 INFO: [pet_c..][Iter:     430, lr:(6.560e-04,6.560e-06,6.560e-05,)] [eta: 0:06:01] loss: 3.7936e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:51:38,190 INFO: [pet_c..][Iter:     440, lr:(6.480e-04,6.480e-06,6.480e-05,)] [eta: 0:05:57] loss: 1.5388e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:51:42,777 INFO: [pet_c..][Iter:     450, lr:(6.400e-04,6.400e-06,6.400e-05,)] [eta: 0:05:53] loss: 2.6566e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:51:47,170 INFO: [pet_c..][Iter:     460, lr:(6.320e-04,6.320e-06,6.320e-05,)] [eta: 0:05:48] loss: 1.6679e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:51:51,541 INFO: [pet_c..][Iter:     470, lr:(6.240e-04,6.240e-06,6.240e-05,)] [eta: 0:05:44] loss: 2.4409e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:51:56,132 INFO: [pet_c..][Iter:     480, lr:(6.160e-04,6.160e-06,6.160e-05,)] [eta: 0:05:40] loss: 3.6600e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:52:00,587 INFO: [pet_c..][Iter:     490, lr:(6.080e-04,6.080e-06,6.080e-05,)] [eta: 0:05:35] loss: 2.9595e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:52:04,672 INFO: [pet_c..][Iter:     500, lr:(6.000e-04,6.000e-06,6.000e-05,)] [eta: 0:05:30] loss: 5.8722e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:52:09,168 INFO: [pet_c..][Iter:     510, lr:(5.920e-04,5.920e-06,5.920e-05,)] [eta: 0:05:26] loss: 6.9677e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:52:13,687 INFO: [pet_c..][Iter:     520, lr:(5.840e-04,5.840e-06,5.840e-05,)] [eta: 0:05:22] loss: 1.5077e+00 Norm_mean: 5.5028e-01 
2024-12-13 13:52:18,128 INFO: [pet_c..][Iter:     530, lr:(5.760e-04,5.760e-06,5.760e-05,)] [eta: 0:05:17] loss: 3.0681e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:52:22,215 INFO: [pet_c..][Iter:     540, lr:(5.680e-04,5.680e-06,5.680e-05,)] [eta: 0:05:13] loss: 5.7123e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:52:26,499 INFO: [pet_c..][Iter:     550, lr:(5.600e-04,5.600e-06,5.600e-05,)] [eta: 0:05:08] loss: 6.6524e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:52:30,985 INFO: [pet_c..][Iter:     560, lr:(5.520e-04,5.520e-06,5.520e-05,)] [eta: 0:05:04] loss: 5.1188e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:52:35,307 INFO: [pet_c..][Iter:     570, lr:(5.440e-04,5.440e-06,5.440e-05,)] [eta: 0:04:59] loss: 1.2675e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:52:39,957 INFO: [pet_c..][Iter:     580, lr:(5.360e-04,5.360e-06,5.360e-05,)] [eta: 0:04:55] loss: 2.7735e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:52:44,349 INFO: [pet_c..][Iter:     590, lr:(5.280e-04,5.280e-06,5.280e-05,)] [eta: 0:04:51] loss: 3.4357e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:52:48,725 INFO: [pet_c..][Iter:     600, lr:(5.200e-04,5.200e-06,5.200e-05,)] [eta: 0:04:46] loss: 6.8403e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:52:53,284 INFO: [pet_c..][Iter:     610, lr:(5.120e-04,5.120e-06,5.120e-05,)] [eta: 0:04:42] loss: 1.9781e-02 Norm_mean: 5.5028e-01 
2024-12-13 13:52:57,474 INFO: [pet_c..][Iter:     620, lr:(5.040e-04,5.040e-06,5.040e-05,)] [eta: 0:04:37] loss: 5.6807e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:53:01,983 INFO: [pet_c..][Iter:     630, lr:(4.960e-04,4.960e-06,4.960e-05,)] [eta: 0:04:33] loss: 5.7379e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:53:06,445 INFO: [pet_c..][Iter:     640, lr:(4.880e-04,4.880e-06,4.880e-05,)] [eta: 0:04:28] loss: 3.3513e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:53:10,548 INFO: [pet_c..][Iter:     650, lr:(4.800e-04,4.800e-06,4.800e-05,)] [eta: 0:04:24] loss: 9.6951e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:53:14,638 INFO: [pet_c..][Iter:     660, lr:(4.720e-04,4.720e-06,4.720e-05,)] [eta: 0:04:19] loss: 2.0203e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:53:19,180 INFO: [pet_c..][Iter:     670, lr:(4.640e-04,4.640e-06,4.640e-05,)] [eta: 0:04:15] loss: 3.9564e-02 Norm_mean: 5.5028e-01 
2024-12-13 13:53:23,582 INFO: [pet_c..][Iter:     680, lr:(4.560e-04,4.560e-06,4.560e-05,)] [eta: 0:04:10] loss: 8.2920e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:53:27,990 INFO: [pet_c..][Iter:     690, lr:(4.480e-04,4.480e-06,4.480e-05,)] [eta: 0:04:06] loss: 2.7288e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:53:32,672 INFO: [pet_c..][Iter:     700, lr:(4.400e-04,4.400e-06,4.400e-05,)] [eta: 0:04:02] loss: 1.4412e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:53:37,395 INFO: [pet_c..][Iter:     710, lr:(4.320e-04,4.320e-06,4.320e-05,)] [eta: 0:03:58] loss: 7.7260e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:53:42,178 INFO: [pet_c..][Iter:     720, lr:(4.240e-04,4.240e-06,4.240e-05,)] [eta: 0:03:53] loss: 2.9936e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:53:46,759 INFO: [pet_c..][Iter:     730, lr:(4.160e-04,4.160e-06,4.160e-05,)] [eta: 0:03:49] loss: 3.6074e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:53:51,102 INFO: [pet_c..][Iter:     740, lr:(4.080e-04,4.080e-06,4.080e-05,)] [eta: 0:03:45] loss: 1.9081e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:53:55,414 INFO: [pet_c..][Iter:     750, lr:(4.000e-04,4.000e-06,4.000e-05,)] [eta: 0:03:40] loss: 8.2223e-02 Norm_mean: 5.5028e-01 
2024-12-13 13:53:59,698 INFO: [pet_c..][Iter:     760, lr:(3.920e-04,3.920e-06,3.920e-05,)] [eta: 0:03:36] loss: 1.0689e+00 Norm_mean: 5.5028e-01 
2024-12-13 13:54:04,239 INFO: [pet_c..][Iter:     770, lr:(3.840e-04,3.840e-06,3.840e-05,)] [eta: 0:03:31] loss: 5.8383e-02 Norm_mean: 5.5028e-01 
2024-12-13 13:54:08,483 INFO: [pet_c..][Iter:     780, lr:(3.760e-04,3.760e-06,3.760e-05,)] [eta: 0:03:27] loss: 5.5521e-02 Norm_mean: 5.5028e-01 
2024-12-13 13:54:12,959 INFO: [pet_c..][Iter:     790, lr:(3.680e-04,3.680e-06,3.680e-05,)] [eta: 0:03:22] loss: 7.3403e-02 Norm_mean: 5.5028e-01 
2024-12-13 13:54:17,085 INFO: [pet_c..][Iter:     800, lr:(3.600e-04,3.600e-06,3.600e-05,)] [eta: 0:03:18] loss: 1.9481e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:54:21,546 INFO: [pet_c..][Iter:     810, lr:(3.520e-04,3.520e-06,3.520e-05,)] [eta: 0:03:13] loss: 4.0568e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:54:25,991 INFO: [pet_c..][Iter:     820, lr:(3.440e-04,3.440e-06,3.440e-05,)] [eta: 0:03:09] loss: 8.4980e-02 Norm_mean: 5.5028e-01 
2024-12-13 13:54:30,328 INFO: [pet_c..][Iter:     830, lr:(3.360e-04,3.360e-06,3.360e-05,)] [eta: 0:03:05] loss: 1.0636e+00 Norm_mean: 5.5028e-01 
2024-12-13 13:54:34,822 INFO: [pet_c..][Iter:     840, lr:(3.280e-04,3.280e-06,3.280e-05,)] [eta: 0:03:00] loss: 9.4671e-02 Norm_mean: 5.5028e-01 
2024-12-13 13:54:39,477 INFO: [pet_c..][Iter:     850, lr:(3.200e-04,3.200e-06,3.200e-05,)] [eta: 0:02:56] loss: 1.3034e+00 Norm_mean: 5.5028e-01 
2024-12-13 13:54:44,005 INFO: [pet_c..][Iter:     860, lr:(3.120e-04,3.120e-06,3.120e-05,)] [eta: 0:02:51] loss: 1.0953e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:54:48,480 INFO: [pet_c..][Iter:     870, lr:(3.040e-04,3.040e-06,3.040e-05,)] [eta: 0:02:47] loss: 7.3853e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:54:52,914 INFO: [pet_c..][Iter:     880, lr:(2.960e-04,2.960e-06,2.960e-05,)] [eta: 0:02:43] loss: 2.0660e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:54:57,008 INFO: [pet_c..][Iter:     890, lr:(2.880e-04,2.880e-06,2.880e-05,)] [eta: 0:02:38] loss: 1.0029e+00 Norm_mean: 5.5028e-01 
2024-12-13 13:55:01,601 INFO: [pet_c..][Iter:     900, lr:(2.800e-04,2.800e-06,2.800e-05,)] [eta: 0:02:34] loss: 1.3301e+00 Norm_mean: 5.5028e-01 
2024-12-13 13:55:05,846 INFO: [pet_c..][Iter:     910, lr:(2.720e-04,2.720e-06,2.720e-05,)] [eta: 0:02:29] loss: 6.7809e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:55:10,038 INFO: [pet_c..][Iter:     920, lr:(2.640e-04,2.640e-06,2.640e-05,)] [eta: 0:02:25] loss: 1.4277e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:55:14,515 INFO: [pet_c..][Iter:     930, lr:(2.560e-04,2.560e-06,2.560e-05,)] [eta: 0:02:20] loss: 6.4744e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:55:18,803 INFO: [pet_c..][Iter:     940, lr:(2.480e-04,2.480e-06,2.480e-05,)] [eta: 0:02:16] loss: 1.2954e+00 Norm_mean: 5.5028e-01 
2024-12-13 13:55:23,330 INFO: [pet_c..][Iter:     950, lr:(2.400e-04,2.400e-06,2.400e-05,)] [eta: 0:02:12] loss: 3.6228e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:55:27,932 INFO: [pet_c..][Iter:     960, lr:(2.320e-04,2.320e-06,2.320e-05,)] [eta: 0:02:07] loss: 2.0314e-02 Norm_mean: 5.5028e-01 
2024-12-13 13:55:32,372 INFO: [pet_c..][Iter:     970, lr:(2.240e-04,2.240e-06,2.240e-05,)] [eta: 0:02:03] loss: 6.2534e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:55:36,887 INFO: [pet_c..][Iter:     980, lr:(2.160e-04,2.160e-06,2.160e-05,)] [eta: 0:01:58] loss: 1.2515e+00 Norm_mean: 5.5028e-01 
2024-12-13 13:55:41,347 INFO: [pet_c..][Iter:     990, lr:(2.080e-04,2.080e-06,2.080e-05,)] [eta: 0:01:54] loss: 1.3551e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:55:45,738 INFO: [pet_c..][Iter:   1,000, lr:(2.000e-04,2.000e-06,2.000e-05,)] [eta: 0:01:50] loss: 2.5490e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:55:50,280 INFO: [pet_c..][Iter:   1,010, lr:(1.920e-04,1.920e-06,1.920e-05,)] [eta: 0:01:45] loss: 5.3307e-02 Norm_mean: 5.5028e-01 
2024-12-13 13:55:54,883 INFO: [pet_c..][Iter:   1,020, lr:(1.840e-04,1.840e-06,1.840e-05,)] [eta: 0:01:41] loss: 1.0993e+00 Norm_mean: 5.5028e-01 
2024-12-13 13:55:59,430 INFO: [pet_c..][Iter:   1,030, lr:(1.760e-04,1.760e-06,1.760e-05,)] [eta: 0:01:36] loss: 4.9769e-02 Norm_mean: 5.5028e-01 
2024-12-13 13:56:03,839 INFO: [pet_c..][Iter:   1,040, lr:(1.680e-04,1.680e-06,1.680e-05,)] [eta: 0:01:32] loss: 1.2154e+00 Norm_mean: 5.5028e-01 
2024-12-13 13:56:08,303 INFO: [pet_c..][Iter:   1,050, lr:(1.600e-04,1.600e-06,1.600e-05,)] [eta: 0:01:28] loss: 2.3147e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:56:12,491 INFO: [pet_c..][Iter:   1,060, lr:(1.520e-04,1.520e-06,1.520e-05,)] [eta: 0:01:23] loss: 5.9467e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:56:16,907 INFO: [pet_c..][Iter:   1,070, lr:(1.440e-04,1.440e-06,1.440e-05,)] [eta: 0:01:19] loss: 7.4289e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:56:21,564 INFO: [pet_c..][Iter:   1,080, lr:(1.360e-04,1.360e-06,1.360e-05,)] [eta: 0:01:14] loss: 2.2712e+00 Norm_mean: 5.5028e-01 
2024-12-13 13:56:26,022 INFO: [pet_c..][Iter:   1,090, lr:(1.280e-04,1.280e-06,1.280e-05,)] [eta: 0:01:10] loss: 1.8908e-02 Norm_mean: 5.5028e-01 
2024-12-13 13:56:30,534 INFO: [pet_c..][Iter:   1,100, lr:(1.200e-04,1.200e-06,1.200e-05,)] [eta: 0:01:05] loss: 6.5693e-02 Norm_mean: 5.5028e-01 
2024-12-13 13:56:35,097 INFO: [pet_c..][Iter:   1,110, lr:(1.120e-04,1.120e-06,1.120e-05,)] [eta: 0:01:01] loss: 1.1840e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:56:39,626 INFO: [pet_c..][Iter:   1,120, lr:(1.040e-04,1.040e-06,1.040e-05,)] [eta: 0:00:57] loss: 4.2240e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:56:43,897 INFO: [pet_c..][Iter:   1,130, lr:(9.600e-05,9.600e-07,9.600e-06,)] [eta: 0:00:52] loss: 4.9155e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:56:47,851 INFO: [pet_c..][Iter:   1,140, lr:(8.800e-05,8.800e-07,8.800e-06,)] [eta: 0:00:48] loss: 7.5964e-02 Norm_mean: 5.5028e-01 
2024-12-13 13:56:52,305 INFO: [pet_c..][Iter:   1,150, lr:(8.000e-05,8.000e-07,8.000e-06,)] [eta: 0:00:43] loss: 6.8081e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:56:56,696 INFO: [pet_c..][Iter:   1,160, lr:(7.200e-05,7.200e-07,7.200e-06,)] [eta: 0:00:39] loss: 1.9924e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:57:01,106 INFO: [pet_c..][Iter:   1,170, lr:(6.400e-05,6.400e-07,6.400e-06,)] [eta: 0:00:34] loss: 1.7320e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:57:05,486 INFO: [pet_c..][Iter:   1,180, lr:(5.600e-05,5.600e-07,5.600e-06,)] [eta: 0:00:30] loss: 4.0406e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:57:10,055 INFO: [pet_c..][Iter:   1,190, lr:(4.800e-05,4.800e-07,4.800e-06,)] [eta: 0:00:26] loss: 6.9432e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:57:14,746 INFO: [pet_c..][Iter:   1,200, lr:(4.000e-05,4.000e-07,4.000e-06,)] [eta: 0:00:21] loss: 2.5247e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:57:19,374 INFO: [pet_c..][Iter:   1,210, lr:(3.200e-05,3.200e-07,3.200e-06,)] [eta: 0:00:17] loss: 1.0767e+00 Norm_mean: 5.5028e-01 
2024-12-13 13:57:23,519 INFO: [pet_c..][Iter:   1,220, lr:(2.400e-05,2.400e-07,2.400e-06,)] [eta: 0:00:12] loss: 2.2527e-01 Norm_mean: 5.5028e-01 
2024-12-13 13:57:27,958 INFO: [pet_c..][Iter:   1,230, lr:(1.600e-05,1.600e-07,1.600e-06,)] [eta: 0:00:08] loss: 2.4925e+00 Norm_mean: 5.5028e-01 
2024-12-13 13:57:32,276 INFO: [pet_c..][Iter:   1,240, lr:(8.000e-06,8.000e-08,8.000e-07,)] [eta: 0:00:03] loss: 6.7006e-02 Norm_mean: 5.5028e-01 
2024-12-13 13:57:36,342 INFO: [pet_c..][Iter:   1,250, lr:(0.000e+00,0.000e+00,0.000e+00,)] [eta: 0:00:00] loss: 1.4517e+00 Norm_mean: 5.5028e-01 
2024-12-13 13:57:36,350 INFO: Save state to /home/iampoo/dlcv2024/final/Concept-Conductor/experiments/pet_cat1/models/edlora_model-latest.pth
2024-12-13 13:57:36,350 INFO: Start validation /home/iampoo/dlcv2024/final/Concept-Conductor/experiments/pet_cat1/models/edlora_model-latest.pth:
