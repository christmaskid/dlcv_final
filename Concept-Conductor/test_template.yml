name: EDLoRA_<name>
manual_seed: 0
mixed_precision: fp16

# dataset and data loader settings
datasets:
  val_vis:
    name: PromptDataset
    prompts: <prompts_path>
    num_samples_per_prompt: 8
    latent_size: [ 4,64,64 ]
    replace_mapping:
      <TOK>: <replace_mapping>
    batch_size_per_gpu: 4

models:
  pretrained_path: <pretrained_path>
  enable_edlora: true  # true means ED-LoRA, false means vallina LoRA

# path
path:
  lora_path: experiments/<name>/models/edlora_model-latest.pth

# validation settings
val:
  compose_visualize: true
  alpha_list: [0, 0.7, 1.0] # 0 means only visualize embedding (without lora weight)
  sample:
    num_inference_steps: <num_inference_steps> #50
    guidance_scale: <guidance_scale> #7.5
